# 학습(training)

학습은 되게 간단하다. train.py 파일에서 원하는 부분만 수정하고 실행하여 주면 된다.  
자주 수정하는 부분을 표기하고 넘어가도록 하겠다.

```py
# def parse_opt
parser.add_argument('--cfg', type=str, default='원하는 모델 경로 선택.yaml', help='model.yaml path')
parser.add_argument('--data', type=str, default=ROOT / 'dataset 정보 경로 선택.yaml', help='dataset.yaml path')
parser.add_argument('--hyp', type=str, default=ROOT / '모델에 맞는 파라미터 경로 설정.yaml', help='hyperparameters path')
parser.add_argument('--batch-size', type=int, default=기본 배치사이즈 설정, help='total batch size for all GPUs, -1 for autobatch')
parser.add_argument('--project', default=ROOT / 'runs/train(프로젝트 폴더 설정)', help='save to project/name')
parser.add_argument('--name', default='프로젝트 이름', help='save to project/name')
```

기본으로 자주 수정하는 것은 이정도이며, 모델을 학습시키면 된다.

# 추론(Inference)

추론은 학습을 통해 만들어진 모델을 실제로 새로운 입력 데이터에 적용하여 결과를 내놓는 단계이다.  
좀 더 간단히 얘기하면 학습된 모델을 test 파일들을 넣어 결과물을 분석하는 단계라고 보면 편할 것 같다. 
코드는 아래의 링크를 통하여 확인할 수 있다.
* 학습된 모델로 test 이미지 Bbox 확인: [https://github.com/MindException/Yolov5_Project/blob/main/WIne_detection/Inference_eval.py](https://github.com/MindException/Yolov5_Project/blob/main/WIne_detection/Inference_eval.py)
* CVAT format으로 변환: [https://github.com/MindException/Yolov5_Project/blob/main/WIne_detection/Inference_to_CVAT.py](https://github.com/MindException/Yolov5_Project/blob/main/WIne_detection/Inference_to_CVAT.py)

# 처리과정
1. 학습된 모델 불러오기
2. bbox 결과 확인
3. CVAT format

## 1. 학습된 모델 불러오기

평가를 하기 위해서는 학습된 모델을 가져와야 한다. 라이브러리는 아래와 같다.

```py
import torch
import cv2
import os
import glob
```

그리고 불러오는 코드를 먼저 살펴보겠다.
```py
# model call
model = torch.hub.load('ultralytics/yolov5', 'custom', path="./result_wine_model/weights/best.pt")

# inference Settings
model.conf = 0.5 # NMS confidence threshold
model.iou = 0.45 # NMS IoU threshold

# use Nvidia cuda
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
```

iou란 정답 box와 예측 box의 교집합 크기 / 합집합 크기 이다. 따라서 일정 수준보다 떨어지면 제외시킨다.  
confidence score은 얼마나 박스 안에 실제로 object가 존재하는지, 그리고 그 class를 얼마나 잘 반영했는지에 대한 것이다. 따라서 이것 또한 Bbox에서 confidence를 threshold아래로 예측한 box는 무시하는 방법이다.

## 2. bbox 결과 확인

먼저 코드를 보고 설명하겠다.
```py
# Image
img = cv2.imread(img_path)

# Inference
results = model(img, size=640)

# Results
bbox = results.xyxy[0]

# Bbox
for box in bbox:
    minX = box[0].item()
    minY = box[1].item()
    maxX = box[2].item()
    maxY = box[3].item()
```

1. 먼저 cv2로 이미지를 불러온다.
2. 불러온 이미지를 학습된 모델에 넣는다.
3. 모델이 이미지에 대한 BBox를 반환한다.
4. BBox 형식은 시작점(x,y)값 그리고 이미지 끝점(x,y)값으로 순서대로 반환한다.

## 3. CVAT format

CVAT format은 아래와 같다.

```xml
<annotations>
    <image id="0" name="adit_mp4-1002_jpg.rf.5e4018e963af1251b3f7e6fd487c479e.jpg" width="640" height="480">
        <box label="Maker-Name" occluded="0" source="manual" xtl="136.969" ytl="219.297" xbr="338.13" ybr="273.325" z_order="0">
        </box>
        <box></box>
    </image>
    <image id="0" name="adit_mp4-1002_jpg.rf.5e4018e963af1251b3f7e6fd487c43249e.jpg" width="640" height="480">
        <box></box>
        <box></box>
        <box></box>
        <box></box>
    </image>
</annotations>
```

위와 같이 태그 안에 태그가 들어가는 식으로 tree구조를 이루는 것을 볼 수 있다.  
이제 자세히 tree구조로 xml파일은 선언하는 방법에 대해 보겠다.  

```py
import xml.etree.ElementTree as ET

tree = ET.ElementTree()
root = ET.Element("annotations")

seen_count = 0

# ㅡㅡㅡㅡ 이미지 반복 ㅡㅡㅡㅡ

tree._setroot(root)
tree.write("test_aug.xml", encoding="utf-8")
```
xml 구조는 매우 단순하여 사용하기 편하다. __ET.ElementTree()__ 를 통하여 tree구조를 선언하여 준다.  
원하는 태그가 생길 경우 __ET.Element()__ 를 통하여 원하는 태그를 선언한다.  

모든 태그가 끝났을 경우 __.setroot()__ 를 통하여 제일 최상위 태그를 선언하여 주고 __wirte()__ 를 통해 파일을 저장하면 끝이난다.
```py
# 이미지 반복
for img_path in image_path :
    # <image id="0" name="adit_mp4-1002_jpg.rf.5e4018e963af1251b3f7e6fd487c479e.jpg" width="640" height="480">
    xml_frame = ET.SubElement(root, "image" , id="%d"%seen_count, name=image_name,
                              width="%d"%w, height="%d"%h)
    
    # ㅡㅡㅡㅡ bbox 반복 ㅡㅡㅡㅡ

    seen_count +=1
```
원하는 태그 밑에 하위태그로 들어가고 싶은 경우에는 __ET.SubElement()__ 를 사용하여 제일 첫 번째 매개변수에 상위로 태그변수명을 입력하여 주면 된다.

```py
# bbox 반복
for box in bbox :
    # <box label="car" occluded="0" source="manual" xtl="346.68" ytl="325.63" xbr="427.46" ybr="404.08" z_order="0"> </box>
    ET.SubElement(xml_frame, "box", label=labels, occluded="0", source="manual", xtl=xtl, ytl=ytl, xbr=xbr, ybr=ybr, z_order="0")
```
위와 동일하게 CVAT 형식에 맞게 bbox를 image 태그 하위에 선언하여주면 끝이난다.